{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWe1Go5UDDJ2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "pip install flow-matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KZvoAQADVkU"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "from torch import nn, Tensor\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import numpy as np\n",
        "\n",
        "# flow_matching\n",
        "from flow_matching.path.scheduler import CondOTScheduler\n",
        "from flow_matching.path import AffineProbPath\n",
        "from flow_matching.solver import Solver, ODESolver\n",
        "from flow_matching.utils import ModelWrapper\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import cm\n",
        "import random\n",
        "\n",
        "\n",
        "# To avoid meshgrid warning\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBDYHXCvE3fl",
        "outputId": "3f93d5d2-9497-4ea6-fc95-bdebe2ab6a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using gpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "    print('Using gpu')\n",
        "else:\n",
        "    device = 'cpu'\n",
        "    print('Using cpu.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iFiPiD4E7Qs",
        "outputId": "54ea7e39-f497-4a3a-918b-9efa9a19497c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bd719348b30>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(int(time.time_ns() % (2**32)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpJb2w6nVzcK"
      },
      "source": [
        "Generating our data. Let's create a circles dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpfrMBmeFrmw"
      },
      "outputs": [],
      "source": [
        "def is_valid_circle(center, radius, circles, min_distance=20):\n",
        "    for existing_circle in circles:\n",
        "        existing_center, existing_radius = existing_circle\n",
        "        distance = ((center[0] - existing_center[0])**2 + (center[1] - existing_center[1])**2)**0.5\n",
        "        if distance < radius + existing_radius + min_distance:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def create_circles_dataset(num_samples=5000, im_size=256):\n",
        "    # Initialize a tensor to store all images\n",
        "    dataset = torch.zeros((num_samples, im_size, im_size))\n",
        "\n",
        "    for sample_idx in range(num_samples):\n",
        "        img = torch.zeros((im_size, im_size), dtype=torch.float32)\n",
        "        num_circles = random.randint(1, 5)\n",
        "        circles = []\n",
        "\n",
        "        for _ in range(num_circles):\n",
        "            while True:\n",
        "                center_x, center_y = random.randint(0, im_size-1), random.randint(0, im_size-1)\n",
        "                radius = random.randint(im_size//10, im_size//5)\n",
        "                if is_valid_circle((center_x, center_y), radius, circles, min_distance=3):\n",
        "                    break\n",
        "\n",
        "            circles.append(((center_x, center_y), radius))\n",
        "\n",
        "            # Create a grid of coordinates\n",
        "            x = torch.arange(im_size).view(-1, 1)\n",
        "            y = torch.arange(im_size).view(1, -1)\n",
        "\n",
        "            # Calculate the distance from the center\n",
        "            distance = (x - center_x)**2 + (y - center_y)**2\n",
        "            # Create a mask for the circle\n",
        "            circle_mask = distance <= radius**2\n",
        "\n",
        "            # Assign random colors to each pixel within the circle\n",
        "            random_colors = torch.randint(240, 256, (im_size, im_size), dtype=torch.float32)\n",
        "            img[circle_mask] = random_colors[circle_mask]\n",
        "\n",
        "        # Store the image in the dataset\n",
        "        dataset[sample_idx] = img\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tLnbPV2_2fF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "im_size = 64\n",
        "dataset = create_circles_dataset(num_samples=20000, im_size=im_size)\n",
        "dataset = dataset.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "lPPT8XLZHS15",
        "outputId": "d6e1b6b6-f714-4394-d061-5f7c21acd0e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bd63e7c8f90>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(dataset[10].squeeze(), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JotjJXk9V4We"
      },
      "source": [
        "Parametrizing our velocity field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-a0CxfiG2tZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(Convolution => [BN] => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNetVelocityField(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder = nn.ModuleList()\n",
        "\n",
        "        # Adjust input channels to accommodate time embedding\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(1, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        in_channels += 1  # Adding 1 for time channel\n",
        "\n",
        "        # Encoder path\n",
        "        for feature in features:\n",
        "            self.encoder.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "\n",
        "        # Decoder path\n",
        "        for feature in reversed(features):\n",
        "            self.decoder.append(\n",
        "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
        "            )\n",
        "            self.decoder.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        # Final output layer\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # Process time embedding\n",
        "        t = t.view(-1, 1)  # Ensure time is in the correct shape\n",
        "        t_emb = self.time_mlp(t).view(x.shape[0], -1, 1, 1)  # Expand to match spatial dimensions\n",
        "        t_emb = t_emb.expand(-1, -1, x.shape[2], x.shape[3])\n",
        "\n",
        "        # Concatenate time embedding with input\n",
        "        x = torch.cat((x, t_emb), dim=1)\n",
        "\n",
        "        skip_connections = []\n",
        "\n",
        "        # Encoder\n",
        "        for layer in self.encoder:\n",
        "            x = layer(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        for idx in range(0, len(self.decoder), 2):\n",
        "            x = self.decoder[idx](x)\n",
        "            skip_connection = skip_connections[idx // 2]\n",
        "            x = torch.cat((x, skip_connection), dim=1)\n",
        "            x = self.decoder[idx + 1](x)\n",
        "\n",
        "        return self.final_conv(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4GU1cS4V8-0"
      },
      "source": [
        "Training our velocity field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-2RWOx_G400",
        "outputId": "347b51a0-288f-4c93-e978-41b3da27dc3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| iter   1000 | 971.56 ms/step | loss 9906.466 \n",
            "| iter   2000 | 975.85 ms/step | loss 9072.688 \n",
            "| iter   3000 | 968.23 ms/step | loss 7237.189 \n",
            "| iter   4000 | 969.21 ms/step | loss 5855.254 \n",
            "| iter   5000 | 958.03 ms/step | loss 5711.798 \n"
          ]
        }
      ],
      "source": [
        "# training arguments\n",
        "lr = 0.0001\n",
        "batch_size = 128\n",
        "iterations = 25000\n",
        "print_every = 1000\n",
        "\n",
        "\n",
        "# velocity field model init\n",
        "vf = UNetVelocityField(in_channels=im_size, out_channels=1).to(device)\n",
        "\n",
        "# instantiate an affine path object\n",
        "path = AffineProbPath(scheduler=CondOTScheduler())\n",
        "\n",
        "# init optimizer\n",
        "optim = torch.optim.Adam(vf.parameters(), lr=lr)\n",
        "losses = []  # Initialize an empty list to store losses\n",
        "# train\n",
        "start_time = time.time()\n",
        "for i in range(iterations):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    # sample data (user's responsibility): in this case, (X_0,X_1) ~ pi(X_0,X_1) = N(X_0|0,I)q(X_1)\n",
        "    x_1 = dataset[torch.randint(0, dataset.shape[0], (batch_size,))]  # Shape: (batch_size, 1, im_size, im_size)\n",
        "    x_1 = x_1.to(device)\n",
        "    x_0 = torch.randn_like(x_1).to(device)\n",
        "\n",
        "    # sample time (user's responsibility)\n",
        "    t = torch.rand(x_1.shape[0]).to(device)\n",
        "\n",
        "    # sample probability path\n",
        "    path_sample = path.sample(t=t, x_0=x_0, x_1=x_1)\n",
        "\n",
        "    # flow matching l2 loss\n",
        "    loss = torch.pow( vf(path_sample.x_t,path_sample.t) - path_sample.dx_t, 2).mean()\n",
        "    losses.append(loss.item())  # Append the loss to the list\n",
        "\n",
        "    # optimizer step\n",
        "    loss.backward() # backward\n",
        "    optim.step() # update\n",
        "\n",
        "    # log loss\n",
        "    if (i+1) % print_every == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print('| iter {:6d} | {:5.2f} ms/step | loss {:8.3f} '\n",
        "              .format(i+1, elapsed*1000/print_every, loss.item()))\n",
        "        start_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VERB8h5q3u7b"
      },
      "outputs": [],
      "source": [
        "plt.semilogy(losses)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvzIJ0TPHELr"
      },
      "outputs": [],
      "source": [
        "class WrappedModel(ModelWrapper):\n",
        "    def forward(self, x: torch.Tensor, t: torch.Tensor, **extras):\n",
        "        return self.model(x, t)\n",
        "\n",
        "wrapped_vf = WrappedModel(vf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLItogCrV_Q7"
      },
      "source": [
        "Generating samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC1MVChaH8u3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# step size for ode solver\n",
        "step_size = 0.0008\n",
        "\n",
        "norm = cm.colors.Normalize(vmax=50, vmin=0)\n",
        "\n",
        "batch_size = 1  # batch size\n",
        "eps_time = 1e-2\n",
        "T = torch.linspace(0,1,100)  # sample times\n",
        "T = T.to(device=device)\n",
        "# x_1 = dataset[torch.randint(0, dataset.shape[0], (batch_size,))]\n",
        "x_init = torch.randn(batch_size, 1, im_size, im_size, device=device)\n",
        "solver = ODESolver(velocity_model=wrapped_vf)  # create an ODESolver class\n",
        "sol = solver.sample(time_grid=T, x_init=x_init, method='midpoint', step_size=step_size, return_intermediates=True)  # sample from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYxWew60H-eE"
      },
      "outputs": [],
      "source": [
        "sol.shape\n",
        "sol = sol.cpu()\n",
        "T = T.cpu()\n",
        "\n",
        "# Calculate the indices of the time steps to plot\n",
        "num_plots = 10\n",
        "plot_indices = np.linspace(0, len(T) - 1, num_plots, dtype=int)\n",
        "\n",
        "# Create the figure and subplots\n",
        "fig, axs = plt.subplots(1, num_plots, figsize=(20, 20))\n",
        "\n",
        "# Iterate over the selected time steps and plot\n",
        "for i, plot_index in enumerate(plot_indices):\n",
        "    axs[i].imshow(sol[plot_index].squeeze(), cmap='gray')\n",
        "    axs[i].set_aspect('equal')\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title('t= %.2f' % (T[plot_index]))  # Use the correct time value\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGM6QpBRh7Iu"
      },
      "outputs": [],
      "source": [
        "plt.imshow(dataset[3].squeeze(), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em5HCmMIYZBI"
      },
      "source": [
        "https://openreview.net/pdf?id=fs2Z2z3GRx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQoWVdwUYYBo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}